{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# --"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-11T13:05:52.824579Z",
     "start_time": "2019-11-11T13:05:52.792577Z"
    }
   },
   "outputs": [],
   "source": [
    "def log_progress(sequence, every=None, size=None, name='Items'):\n",
    "    \"\"\"https://habr.com/ru/post/276725/\n",
    "    способ создания красивых прогресс-баров\n",
    "    см. также pypi.python.org/pypi/tqdm\"\"\"\n",
    "    from ipywidgets import IntProgress, HTML, VBox\n",
    "    from IPython.display import display\n",
    "\n",
    "    is_iterator = False\n",
    "    if size is None:\n",
    "        try:\n",
    "            size = len(sequence)\n",
    "        except TypeError:\n",
    "            is_iterator = True\n",
    "    if size is not None:\n",
    "        if every is None:\n",
    "            if size <= 200:\n",
    "                every = 1\n",
    "            else:\n",
    "                every = int(size / 200)     # every 0.5%\n",
    "    else:\n",
    "        assert every is not None, 'sequence is iterator, set every'\n",
    "\n",
    "    if is_iterator:\n",
    "        progress = IntProgress(min=0, max=1, value=1)\n",
    "        progress.bar_style = 'info'\n",
    "    else:\n",
    "        progress = IntProgress(min=0, max=size, value=0)\n",
    "    label = HTML()\n",
    "    box = VBox(children=[label, progress])\n",
    "    display(box)\n",
    "\n",
    "    index = 0\n",
    "    try:\n",
    "        for index, record in enumerate(sequence, 1):\n",
    "            if index == 1 or index % every == 0:\n",
    "                if is_iterator:\n",
    "                    label.value = '{name}: {index} / ?'.format(\n",
    "                        name=name,\n",
    "                        index=index\n",
    "                    )\n",
    "                else:\n",
    "                    progress.value = index\n",
    "                    label.value = u'{name}: {index} / {size}'.format(\n",
    "                        name=name,\n",
    "                        index=index,\n",
    "                        size=size\n",
    "                    )\n",
    "            yield record\n",
    "    except:\n",
    "        progress.bar_style = 'danger'\n",
    "        raise\n",
    "    else:\n",
    "        progress.bar_style = 'success'\n",
    "        progress.value = index\n",
    "        label.value = \"{name}: {index}\".format(\n",
    "            name=name,\n",
    "            index=str(index or '?')\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-11T13:05:54.013647Z",
     "start_time": "2019-11-11T13:05:52.826579Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0113e540670246ea8879275535060f2e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HTML(value='')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# прогресс-бар числом - для случаев while и т.п.\n",
    "from ipywidgets import HTML\n",
    "from IPython.display import display\n",
    "from time import sleep\n",
    "label = HTML()\n",
    "display(label)\n",
    "for x in range(10):\n",
    "    label.value = str(x)\n",
    "    sleep(0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-11T13:05:54.033648Z",
     "start_time": "2019-11-11T13:05:54.015647Z"
    }
   },
   "outputs": [],
   "source": [
    "# вычисляет полный размер объекта в памяти\n",
    "\n",
    "import sys\n",
    "from types import ModuleType, FunctionType\n",
    "from gc import get_referents\n",
    "\n",
    "# Custom objects know their class.\n",
    "# Function objects seem to know way too much, including modules.\n",
    "# Exclude modules as well.\n",
    "BLACKLIST = type, ModuleType, FunctionType\n",
    "\n",
    "\n",
    "def getmemsize(obj):\n",
    "    \"\"\"sum size of object & members.\"\"\"\n",
    "    if isinstance(obj, BLACKLIST):\n",
    "        raise TypeError('getsize() does not take argument of type: '+ str(type(obj)))\n",
    "    seen_ids = set()\n",
    "    size = 0\n",
    "    objects = [obj]\n",
    "    while objects:\n",
    "        need_referents = []\n",
    "        for obj in objects:\n",
    "            if not isinstance(obj, BLACKLIST) and id(obj) not in seen_ids:\n",
    "                seen_ids.add(id(obj))\n",
    "                size += sys.getsizeof(obj)\n",
    "                need_referents.append(obj)\n",
    "        objects = get_referents(*need_referents)\n",
    "    return size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-11T13:05:54.246661Z",
     "start_time": "2019-11-11T13:05:54.041649Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# проверка на симлинки\n",
    "# стандартная проверка в windows junction-ы не считает симлинками\n",
    "\n",
    "from ctypes import *\n",
    "from ctypes.wintypes import *\n",
    "\n",
    "FILE_ATTRIBUTE_REPARSE_POINT = 0x00400\n",
    "INVALID_FILE_ATTRIBUTES = 0xFFFFFFFF\n",
    "\n",
    "kernel32 = WinDLL('kernel32')\n",
    "GetFileAttributesW = kernel32.GetFileAttributesW\n",
    "GetFileAttributesW.restype = DWORD\n",
    "GetFileAttributesW.argtypes = (LPCWSTR,) #lpFileName In\n",
    "\n",
    "def islink(path):\n",
    "    result = GetFileAttributesW(path)\n",
    "    if result == INVALID_FILE_ATTRIBUTES:\n",
    "        raise WinError()\n",
    "    return bool(result & FILE_ATTRIBUTE_REPARSE_POINT)\n",
    "\n",
    "islink(r'D:\\Users\\feelus\\Local Settings')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-11T13:05:54.605681Z",
     "start_time": "2019-11-11T13:05:54.252661Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('C:\\\\a\\\\b', 'c')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.path.split(r'C:\\a\\b\\c')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-11T13:05:54.766690Z",
     "start_time": "2019-11-11T13:05:54.613682Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'a\\\\c\\\\b'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def slash_replacer(s):\n",
    "    while s[0]=='\\\\':\n",
    "        s = s[1:]\n",
    "    while s[-1]=='\\\\':\n",
    "        s = s[:-1]\n",
    "    return s\n",
    "def my_path_join_a(*ll):\n",
    "    return '\\\\'.join([slash_replacer(s) for s in ll])\n",
    "def my_path_join_l(ll):\n",
    "    return '\\\\'.join([slash_replacer(s) for s in ll])\n",
    "my_path_join_a('a\\\\c','b')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-11T13:05:54.872696Z",
     "start_time": "2019-11-11T13:05:54.778691Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from stat import *\n",
    "\n",
    "def scan(rootpath):\n",
    "    \"\"\"сканирует заданную папку и возвращает дерево:\n",
    "    имя_папки : {...}\n",
    "    имя_файла : [размер]\"\"\"\n",
    "    root = {}\n",
    "    #rootpath = 'D:\\\\'\n",
    "    total_size = 0\n",
    "    ts_printed = 0\n",
    "\n",
    "    label = HTML()\n",
    "    display(label)\n",
    "    \n",
    "    for curdir, indirs, infiles in os.walk(rootpath):\n",
    "        path = curdir\n",
    "        folders = []\n",
    "        while path != rootpath:\n",
    "            #print(path)\n",
    "            path, folder = os.path.split(path)\n",
    "            folders.append(folder)\n",
    "\n",
    "        #print(curdir)\n",
    "        #print(folders)\n",
    "        curroot = root\n",
    "        try:\n",
    "            for i in reversed(folders):\n",
    "                curroot = curroot[i]\n",
    "        except:\n",
    "            #print('path is apsent in tree:',curdir)\n",
    "            continue\n",
    "\n",
    "        for d in indirs:\n",
    "            cur_d = my_path_join_a(curdir,d)\n",
    "            try:\n",
    "                mode = os.stat(cur_d).st_mode\n",
    "                islnk = islink(cur_d)\n",
    "            except:\n",
    "                print(\"can't check stat of dir:\",cur_d)\n",
    "                continue\n",
    "            if not S_ISDIR(mode) or islnk:\n",
    "                print(\"this dir is not dir:\",cur_d,mode)\n",
    "                continue\n",
    "            curroot[d]={}\n",
    "        for f in infiles:\n",
    "            cur_f = my_path_join_a(curdir,f)\n",
    "            try:\n",
    "                st = os.stat(cur_f)\n",
    "                mode = st.st_mode\n",
    "                size = st.st_size\n",
    "                islnk = islink(cur_d)\n",
    "            except:\n",
    "                print(\"can't check stat of file:\",cur_f)\n",
    "                continue\n",
    "            if not S_ISREG(mode):\n",
    "                print(\"this file is not file:\",cur_f,mode)\n",
    "                continue\n",
    "            if islnk:\n",
    "                print(\"this file is not usual:\",cur_f,mode)\n",
    "            curroot[f]=[size]\n",
    "            \n",
    "            total_size+=size\n",
    "            if ts_printed<int(total_size/1024/1024/1024):\n",
    "                ts_printed = int(total_size/1024/1024/1024)\n",
    "                label.value = str(ts_printed)+' GB scanned'\n",
    "            \n",
    "    label.value = str(ts_printed)+' GB scanned - completed'\n",
    "    return root\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-11T13:05:54.950701Z",
     "start_time": "2019-11-11T13:05:54.876697Z"
    }
   },
   "outputs": [],
   "source": [
    "def tree_iterator(tree):\n",
    "    \"\"\"проходится по всему дереву\n",
    "    на каждом узле(листе) возвращает пару (путь, значение)\n",
    "    где путь - список имен, по которым надо добираться по дереву до значения\"\"\"\n",
    "    for k,v in tree.items():\n",
    "        if type(v)==dict:\n",
    "            for path,v2 in tree_iterator(v):\n",
    "                path.insert(0,k)\n",
    "                yield path,v2\n",
    "        else:\n",
    "            yield [k],v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-11T13:05:55.161713Z",
     "start_time": "2019-11-11T13:05:54.959701Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(['a'], 1)\n",
      "(['b', 'c'], 2)\n",
      "(['b', 'd'], 3)\n"
     ]
    }
   ],
   "source": [
    "r = {'a':1,'b':{'c':2,'d':3}}\n",
    "for x in tree_iterator(r):\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-11T13:05:55.252718Z",
     "start_time": "2019-11-11T13:05:55.163713Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_subtree(root,path):\n",
    "    \"\"\"берет корень и путь, проходит по пути, и возвращает то, где оказался\"\"\"\n",
    "    if len(path)==0: return root\n",
    "    else: return get_subtree(root[path[0]],path[1:])\n",
    "def make_subdir(root,path):\n",
    "    \"\"\"берет корень и путь, проходит по пути и создает его, если его нет\"\"\"\n",
    "    if len(path)==0: return root\n",
    "    else: \n",
    "        if path[0] not in root: root[path[0]]={}\n",
    "        return make_subdir(root[path[0]],path[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-11T13:05:55.941758Z",
     "start_time": "2019-11-11T13:05:55.254718Z"
    }
   },
   "outputs": [],
   "source": [
    "import hashlib\n",
    "def md5(fname):\n",
    "    \"\"\"вычисляет хеш файла по его пути\"\"\"\n",
    "    hash_md5 = hashlib.md5()\n",
    "    with open(fname, \"rb\") as f:\n",
    "        for chunk in iter(lambda: f.read(4096), b\"\"):\n",
    "            hash_md5.update(chunk)\n",
    "    return hash_md5.hexdigest()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-11T13:05:56.034763Z",
     "start_time": "2019-11-11T13:05:55.943758Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_diplics_by_size(root):\n",
    "    root_by_size={} # map: размер -> множество файлов\n",
    "    # файл - tuple из пути к файлу\n",
    "    for x,v in tree_iterator(root):\n",
    "        size = v[0]\n",
    "        file = tuple(x)\n",
    "        #print(x,v,size)\n",
    "        if size in root_by_size:\n",
    "            root_by_size[size].add(file)\n",
    "        else:\n",
    "            root_by_size[size] = {file}\n",
    "\n",
    "    # map размер -> кол-во повторений (если их >1)\n",
    "    dups_by_size = [(i,len(root_by_size[i])) for i in reversed(sorted(root_by_size.keys())) \\\n",
    "                   if len(root_by_size[i])!=1]\n",
    "    tot_s=0\n",
    "    tot_ss = 0\n",
    "    tot_n = 0\n",
    "    for s,n in dups_by_size:\n",
    "        tot_s+=s*(n-1)\n",
    "        tot_ss+=s*(n)\n",
    "        tot_n+=n\n",
    "    print('by size:')\n",
    "    print('размер повторений', '%.3f'%(tot_ss/1024/1024),'MB')\n",
    "    print('размер лишнего   ', '%.3f'%(tot_s/1024/1024),'MB')\n",
    "    print('кол-во повторений', tot_n)\n",
    "    print('кол-во лишнего   ', tot_n-len(dups_by_size))\n",
    "    return root_by_size,dups_by_size\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-11T13:05:56.160770Z",
     "start_time": "2019-11-11T13:05:56.042763Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def list_duplics_by_size(root_by_size,dups_by_size):\n",
    "    \"\"\"перечисляет все повторы по размеру\"\"\"\n",
    "    for s,n in dups_by_size:\n",
    "        for p in sorted(root_by_size[s]):\n",
    "            yield s,p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-11T13:05:56.280777Z",
     "start_time": "2019-11-11T13:05:56.162770Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def is_subpath(subpath,path):\n",
    "    \"\"\"сначала длинный, потом короткий\"\"\"\n",
    "    if len(subpath)<len(path):\n",
    "        return False\n",
    "    for i in range(len(path)):\n",
    "        if subpath[i]!=path[i]:\n",
    "            return False\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-11T13:05:56.422785Z",
     "start_time": "2019-11-11T13:05:56.282777Z"
    },
    "code_folding": [
     89
    ]
   },
   "outputs": [],
   "source": [
    "# загружаем хэши\n",
    "import json, codecs\n",
    "\n",
    "def load_hashes(hash_path,prefix):\n",
    "    \"\"\"загружаем хэши, вычисляем хэши, сохраняем хэши\"\"\"\n",
    "    try:\n",
    "        with codecs.open(hash_path,'r', encoding='utf-8') as file:\n",
    "            old_root = file.read()\n",
    "            old_root = json.loads(old_root)\n",
    "            print('readed',hash_path)\n",
    "            print(old_root.keys())\n",
    "    except BaseException as e:\n",
    "        print(e)\n",
    "        old_root = {}\n",
    "    return old_root\n",
    "\n",
    "def calc_hashes(root,old_root,prefix,root_by_size,dups_by_size):\n",
    "    #assert len(prefix)>=1\n",
    "    if type(prefix)==set:\n",
    "        if len(prefix)==1:\n",
    "            prefix = next(iter(prefix))\n",
    "        else:\n",
    "            prefix_list = prefix\n",
    "            prefix = []\n",
    "    #print('prefix=',prefix)\n",
    "    def del_old_hashes(root,old_root):\n",
    "        for_del = set()\n",
    "        for k in old_root:\n",
    "            if k not in root:\n",
    "                #for_del.add(k)#del old_root[k]\n",
    "                continue\n",
    "            if type(root[k])==dict and type(old_root[k])==dict:\n",
    "                del_old_hashes(root[k],old_root[k])\n",
    "            elif type(root[k])==list and type(old_root[k])==list:\n",
    "                if root[k][0]!=old_root[k][0]:\n",
    "                    for_del.add(k)#del old_root[k]\n",
    "                elif len(old_root[k])==2 and len(root[k])==1:\n",
    "                    root[k].append(old_root[k][1])\n",
    "            else:\n",
    "                for_del.add(k)#del old_root[k]\n",
    "        for k in for_del:\n",
    "            del old_root[k]\n",
    "    del_old_hashes(root,old_root)\n",
    "\n",
    "    # вычисляем хэши\n",
    "    tot_ss = 0\n",
    "    tot_n = 0\n",
    "    counter2 = 0\n",
    "\n",
    "    label = HTML()\n",
    "    display(label)\n",
    "\n",
    "    calculated = set()\n",
    "    for s,p in list_duplics_by_size(root_by_size,dups_by_size):\n",
    "        tot_ss += s\n",
    "        tot_n+=1\n",
    "        counter2+=1\n",
    "        p = list(prefix)+list(p)\n",
    "        try:\n",
    "            old_fs = get_subtree(old_root,p)\n",
    "            if len(old_fs)>=2:\n",
    "                hashh = old_fs[1]\n",
    "            else:\n",
    "                fs = get_subtree(root,p)\n",
    "                if len(fs)>=2:\n",
    "                    hashh = fs[1]\n",
    "                else: raise\n",
    "\n",
    "        except:\n",
    "            #hashh = md5(os.path.join(*p))\n",
    "            try:\n",
    "                tmp_p = my_path_join_l(p)\n",
    "                calculated.add((s,tmp_p))\n",
    "                hashh = md5(tmp_p)\n",
    "            except BaseException as e:\n",
    "                print(e)\n",
    "                continue\n",
    "            if counter2%10==0 or tot_n<10:\n",
    "                label.value = str(tot_n)+' files,  ' +'%.3f'%(tot_ss/1024/1024)+' MB'\n",
    "        fs = get_subtree(root,p)\n",
    "        if len(fs) == 1: fs.append(hashh)\n",
    "        else:            fs[1] = hashh\n",
    "        #old_fs = get_subtree(old_root,p)\n",
    "        #if len(old_fs) == 1: old_fs.append(hashh)\n",
    "        #else:            old_fs[1] = hashh\n",
    "        #print(hashh+'\\t'+my_path_join_a(rootpath_YD,*p))\n",
    "    label.value = str(tot_n)+' files,  ' +'%.3f'%(tot_ss/1024/1024)+' MB - completed'\n",
    "    return calculated\n",
    "\n",
    "def unload_hashes(root,hash_path,prefix):\n",
    "    #assert len(prefix)>=1\n",
    "    if type(prefix)==set:\n",
    "        if len(prefix)==1:\n",
    "            prefix = next(iter(prefix))\n",
    "        else:\n",
    "            prefix_list = prefix\n",
    "            prefix = []\n",
    "    # сохраняем хэши\n",
    "    if len(prefix)>0:\n",
    "        tmp = make_subdir(old_root,prefix[:-1])\n",
    "        subroot = get_subtree(root,prefix)\n",
    "        tmp[prefix[-1]] = subroot\n",
    "    else:\n",
    "        for prefix in prefix_list:\n",
    "            tmp = make_subdir(old_root,prefix[:-1])\n",
    "            subroot = get_subtree(root,prefix)\n",
    "            tmp[prefix[-1]] = subroot\n",
    "    try:\n",
    "        print('start writing')\n",
    "        with codecs.open(hash_path,'w', encoding='utf-8') as file:\n",
    "            s = json.dumps(old_root,indent='\\t',ensure_ascii=False)\n",
    "            file.write(s)\n",
    "            print('writed',hash_path)\n",
    "    except BasicException as e:\n",
    "        print('start writing with exception',e)\n",
    "        with codecs.open(hash_path,'w', encoding='utf-8') as file:\n",
    "            s = json.dumps(old_root,indent='\\t',ensure_ascii=False)\n",
    "            file.write(s)\n",
    "            print('writed',hash_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-11T13:05:56.552793Z",
     "start_time": "2019-11-11T13:05:56.428785Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def get_duplics_by_hash(root,root_by_size,dups_by_size):\n",
    "    \"\"\"повторы по хэшам (и размеру)\"\"\"\n",
    "\n",
    "    dups_by_hash = {}\n",
    "    for s,n in dups_by_size:\n",
    "        for p in sorted(root_by_size[s]):\n",
    "            fdata = get_subtree(root,p)\n",
    "            if len(fdata)<2: continue\n",
    "            if len(fdata)>2: del fd[2:]\n",
    "            hashh = fdata[1]\n",
    "            if (s,hashh) in dups_by_hash:\n",
    "                dups_by_hash[(s,hashh)].add(p)\n",
    "            else:\n",
    "                dups_by_hash[(s,hashh)] = {p}\n",
    "    dups_by_hash = {s_h:pp for (s_h,pp) in dups_by_hash.items() if len(pp)>1}\n",
    "    tot_s=0\n",
    "    tot_ss = 0\n",
    "    tot_n = 0\n",
    "    for s_h,pp in dups_by_hash.items():\n",
    "        n = len(pp)\n",
    "        s = s_h[0]\n",
    "        tot_s+=s*(n-1)\n",
    "        tot_ss+=s*(n)\n",
    "        tot_n+=n\n",
    "    print('by hash:')\n",
    "    print('размер всего  ', '%.3f'%(tot_ss/1024/1024),'MB')\n",
    "    print('размер лишнего', '%.3f'%(tot_s/1024/1024),'MB')\n",
    "    print('кол-во повторений', tot_n)\n",
    "    print('кол-во лишнего   ', tot_n-len(dups_by_hash))\n",
    "    return dups_by_hash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-11T13:05:56.769805Z",
     "start_time": "2019-11-11T13:05:56.556793Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def ignore_files(dups_by_hash):\n",
    "    for k in ignored_files:\n",
    "        if k in dups_by_hash: del dups_by_hash[k]\n",
    "\n",
    "    tot_s=0\n",
    "    tot_ss=0\n",
    "    tot_n=0\n",
    "    for s_h,pp in dups_by_hash.items():\n",
    "        n = len(pp)\n",
    "        s = s_h[0]\n",
    "        tot_s+=s*(n-1)\n",
    "        tot_ss+=s*(n)\n",
    "        tot_n+=n\n",
    "    print('by hash, ignore files:')\n",
    "    print('размер всего  ', '%.3f'%(tot_ss/1024/1024),'MB')\n",
    "    print('размер лишнего', '%.3f'%(tot_s/1024/1024),'MB')\n",
    "    print('кол-во повторений', tot_n)\n",
    "    print('кол-во лишнего   ', tot_n-len(dups_by_hash))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-11T13:05:56.859810Z",
     "start_time": "2019-11-11T13:05:56.771805Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def ignore_dirs(root,prefix,dups_by_hash):\n",
    "    if type(prefix)==set:\n",
    "        if len(prefix)==1:\n",
    "            prefix = next(iter(prefix))\n",
    "        else:\n",
    "            prefix_list = prefix\n",
    "            prefix = []\n",
    "    print('prefix=',prefix)\n",
    "    def ignore_subdirs(subroot,cp): # common path\n",
    "        #print('start:',cp)\n",
    "        for k,f in subroot.items():\n",
    "            if type(f)==dict:\n",
    "                ignore_subdirs(f,cp)\n",
    "            elif type(f)==list and len(f)>=2:\n",
    "                sh = tuple(f[:2]) # size hash\n",
    "                same = True\n",
    "                if sh in dups_by_hash:\n",
    "                    #print('try to del',sh)\n",
    "                    #print('\\t',cp)\n",
    "                    for path in dups_by_hash[sh]:\n",
    "                        path = list(prefix)+list(path)\n",
    "                        #print('\\t',path)\n",
    "                        if not is_subpath(path,cp):\n",
    "                            same = False\n",
    "                            break\n",
    "                    if same:\n",
    "                        #print('del')\n",
    "                        del dups_by_hash[sh]\n",
    "    for d in ignored_dirs:\n",
    "        try:\n",
    "            d = d.split('\\\\')\n",
    "            #try:\n",
    "            subroot = get_subtree(root,d)\n",
    "            #except KeyError:\n",
    "            #    print('key error')\n",
    "            #except BaseException as e:\n",
    "            #    print('111',type(e),e)\n",
    "            ignore_subdirs(subroot,d)\n",
    "        except KeyError:\n",
    "            pass\n",
    "            #print('key error')\n",
    "        except BaseException as e:\n",
    "            print(type(e),e)\n",
    "        \n",
    "    tot_s=0\n",
    "    tot_ss=0\n",
    "    tot_n=0\n",
    "    for s_h,pp in dups_by_hash.items():\n",
    "        n = len(pp)\n",
    "        s = s_h[0]\n",
    "        tot_s+=s*(n-1)\n",
    "        tot_ss+=s*(n)\n",
    "        tot_n+=n\n",
    "    print('by hash, ignore dirs:')\n",
    "    print('размер всего  ', '%.3f'%(tot_ss/1024/1024),'MB')\n",
    "    print('размер лишнего', '%.3f'%(tot_s/1024/1024),'MB')\n",
    "    print('кол-во повторений', tot_n)\n",
    "    print('кол-во лишнего   ', tot_n-len(dups_by_hash))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-11T13:05:57.122825Z",
     "start_time": "2019-11-11T13:05:56.861810Z"
    },
    "code_folding": [
     0,
     18
    ]
   },
   "outputs": [],
   "source": [
    "def del_void_dirs(root,path):\n",
    "    #print(path)\n",
    "    fordel = set()\n",
    "    for k,f in root.items():\n",
    "        if type(f)==dict:\n",
    "            del_void_dirs(f,path+[k])\n",
    "            #print(k,len(f))\n",
    "            if len(f)==0:\n",
    "                fordel.add(k)\n",
    "    for k in fordel:\n",
    "        p = my_path_join_l(path+[k])\n",
    "        try: \n",
    "            os.rmdir(p)\n",
    "            print('del dir',p)\n",
    "            del root[k]\n",
    "        except OSError as e:\n",
    "            print(e,p)\n",
    "\n",
    "def del_dir(root,prefix,dups_by_hash,base_dir,del_dir, stop_size=0):\n",
    "    if type(prefix)==set:\n",
    "        if len(prefix)==1:\n",
    "            prefix = next(iter(prefix))\n",
    "        else:\n",
    "            prefix_list = prefix\n",
    "            prefix = []\n",
    "    print('prefix=',prefix)\n",
    "    base_dir = base_dir.split('\\\\')\n",
    "    del_dir  =  del_dir.split('\\\\')\n",
    "    try:\n",
    "        with codecs.open('deleted.json','r', encoding='utf-8') as file:\n",
    "            del_root = file.read()\n",
    "            del_root = json.loads(del_root)\n",
    "            print('readed',hash_path)\n",
    "            print(del_root.keys())\n",
    "    except BaseException as e:\n",
    "        print(e)\n",
    "        del_root = {}\n",
    "\n",
    "    def save_deleted(del_root,path,sh):\n",
    "        if len(path)==1:\n",
    "            del_root[path[0]]=sh\n",
    "        else:\n",
    "            if path[0] not in del_root:\n",
    "                del_root[path[0]]={}\n",
    "            save_deleted(del_root[path[0]],path[1:],sh)\n",
    "    def del_subdir(base_root,base_path): # рекурсивно проходимся по базовой директории\n",
    "        fordel_gr = set()\n",
    "        for k,f in base_root.items():\n",
    "            if type(f)==dict:\n",
    "                del_subdir(f,base_path+[k])\n",
    "            elif type(f)==list and len(f)>=2: # если указан хеш\n",
    "                sh = tuple(f[:2]) # size hash\n",
    "                if sh[0]>=stop_size and sh in dups_by_hash:        # и он содержится в дубликатах\n",
    "                    #print('try to del',sh)\n",
    "                    #print('\\t',cp)\n",
    "                    fordel = set()\n",
    "                    for path in dups_by_hash[sh]: # по всем файлам этого дубликата\n",
    "                        path = list(prefix)+list(path)\n",
    "                        #print('check')\n",
    "                        #print('\\t',path)\n",
    "                        #print('\\t',is_subpath(path,base_dir),base_dir)\n",
    "                        #print('\\t',is_subpath(path,del_dir),del_dir)\n",
    "                        # проверить, что путь не содержится в base_dir и содержится в del_dir\n",
    "                        if not is_subpath(path,base_dir) and is_subpath(path,del_dir):\n",
    "                            fordel.add(tuple(path[len(prefix):]))\n",
    "                            p = my_path_join_l(path)\n",
    "                            # удаляем с диска\n",
    "                            try: \n",
    "                                os.remove(p)\n",
    "                                print('del',sh,p)\n",
    "                                save_deleted(del_root,path,sh)\n",
    "                                # удаляем из root\n",
    "                                try:\n",
    "                                    tmp = get_subtree(root,path[:-1])\n",
    "                                    del tmp[path[-1]]\n",
    "                                except KeyError:\n",
    "                                    print('уже удален из root',p)\n",
    "                            except OSError as e:\n",
    "                                print(e,p)\n",
    "                    # удаляем из dups_by_hash\n",
    "                    #print('from',dups_by_hash[sh])\n",
    "                    #print('del',fordel)\n",
    "                    dups_by_hash[sh] = dups_by_hash[sh] - fordel\n",
    "                    #print(sh,len(dups_by_hash[sh]))\n",
    "                    if len(dups_by_hash[sh])<=1:\n",
    "                        fordel_gr.add(sh)\n",
    "        for sh in fordel_gr:\n",
    "            del dups_by_hash[sh]\n",
    "            \n",
    "    del_subdir(get_subtree(root,base_dir),base_dir)\n",
    "\n",
    "    try:\n",
    "        print('start writing')\n",
    "        with codecs.open('deleted.json','w', encoding='utf-8') as file:\n",
    "            s = json.dumps(del_root,indent='\\t',ensure_ascii=False)\n",
    "            file.write(s)\n",
    "            print('writed','deleted.json')\n",
    "    except BasicException as e:\n",
    "        print('start writing with exception',e)\n",
    "        with codecs.open('deleted.json','w', encoding='utf-8') as file:\n",
    "            s = json.dumps(del_root,indent='\\t',ensure_ascii=False)\n",
    "            file.write(s)\n",
    "            print('writed','deleted.json')\n",
    "\n",
    "    del_void_dirs(get_subtree(root,del_dir),del_dir)\n",
    "    if len(del_dir)>1 and len(get_subtree(root,del_dir))==0:\n",
    "        p = my_path_join_l(del_dir)\n",
    "        try: \n",
    "            os.rmdir(p)\n",
    "            print('del dir',p)\n",
    "            del get_subtree(root,del_dir[:-1])[del_dir[-1]]\n",
    "        except OSError as e:\n",
    "            print(e,p)\n",
    "    \n",
    "    tot_s=0\n",
    "    tot_ss=0\n",
    "    tot_n=0\n",
    "    for s_h,pp in dups_by_hash.items():\n",
    "        n = len(pp)\n",
    "        s = s_h[0]\n",
    "        tot_s+=s*(n-1)\n",
    "        tot_ss+=s*(n)\n",
    "        tot_n+=n\n",
    "    print('by hash after deletion:')\n",
    "    print('размер всего  ', '%.3f'%(tot_ss/1024/1024),'MB')\n",
    "    print('размер лишнего', '%.3f'%(tot_s/1024/1024),'MB')\n",
    "    print('кол-во повторений', tot_n)\n",
    "    print('кол-во лишнего   ', tot_n-len(dups_by_hash))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-11T13:05:57.281834Z",
     "start_time": "2019-11-11T13:05:57.124825Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "ignored_files = {\n",
    "    (4_021_049, \"323c0fd51071400b51eedb1be90a8188\" ), # программы-установщики\\_крякнутые\\activators\\222-3927\\\n",
    "    (7_163_744, 'db7796e33b0a6925fa0d2f5a14c3b0c0'),\n",
    "    (7_161_696, \"0676e5f63b467b2520b5b794ee9cac1e\" ),\n",
    "    (7_161_696, \"c6171d6673c80f2d9f53229fc8e74e93\" ),\n",
    "    (3_141_496, \"7efe66e76728eb555eab03f2c94779f7\" ),\n",
    "    (2_911_096, \"957dad99c1df5728fd0fda142c2ae976\" ),\n",
    "    (1_290_752, \"c9ae332b021335f84b117e0f3e0dc0c4\" ), # _programming_arxiv\\src_2013\\work\\q_client   2\n",
    "    (2_847_232, \"cbbd8381d595a5f5b15f4e9745a048f0\" ), # _programming_arxiv\\src_2013\\work/q_client(2)\n",
    "    (10_137_600, \"d3c70c355594167db4ebc96fe7eaf36c\" ),\n",
    "    (3_548_698, \"cd2f57342d07298cb7fa4d33e8e79f44\" ), # _programming_arxiv\\_networks\\Томсон Л.Разработка WEB-приложений на PHP и MySQL.Диасофт.[RUS,672с.,2003]\\Томсон Л.Разработка WEB-приложений на PHP и MySQL.CD\n",
    "    (3_160_035, \"407859fb8a10cc96871b896a3c977135\" ),\n",
    "    (2_998_523, \"fb29dc1e6cbb7dfaa631a4ec737c1619\" ),\n",
    "    (1_184_499, \"9f934a8a7b9172bcb0eff8cd38662e29\" ), # _programming_arxiv\\lang_delphy_pascal\\research\\консоль\\Windows.pas\n",
    "    (765_794, \"865282cd4a95ff4bbfa5b91bf9a1a148\" ),   # _programming_arxiv\\lang_delphy_pascal\\lang_pascal\\compilators\\BPdos\\intrfcBIN\\TURBO.TPH\n",
    "    (614_785, \"faed282f3f00a30a3c00697d77487a9a\" ),   # _programming_arxiv\\lang_delphy_pascal\\lang_pascal\\compilators\\BPdos\\intrfcBIN\\TVISION.TPH\n",
    "    (2_867_749, \"f0c353b8ae07d40e1738c4ac6f608cd0\" ), # _programming_arxiv\\lang_delphy_pascal\n",
    "    (3_147_048, \"a7e8772270e9d0e5d577da40e6d87679\" ), # _физика\\3_квантовые вычисления\\QC\\bloch3dapp\n",
    "    (2_957_997, \"3c7698a8f64a654710ac8d1953e4c3c0\" ),\n",
    "    (658_776, \"48d07aaf49aa92813ceb7bbd55cb4f0b\" ),   # fonts_cnt.css\n",
    "    (1_401_573, \"251435ee12b6394452cd9126314323d6\" ), # _programming\\talbot\n",
    "    (1_301_549, \"d3ffe8ea7d60db1d6eeb9643bfd7c5c5\" ),\n",
    "    (1_704_635, \"aec595bb8401ffce2bba070fb4ae7eea\" ), # _физика\\3_квантовые вычисления\\QC\\bloch3dapp\n",
    "    (436_089, \"c64bcbea7a619d50f3647156c7b98809\" ),   # jquery-ui-1.10.2.custom.js\n",
    "    (92_629, \"397754ba49e9e0cf4e7c190da78dda05\" ),    # jquery.min.js\n",
    "    (5_814, \"e95a70ca6171d9b12a6188c4549d6e30\" ),     # .css\n",
    "    (2_344, \"c505889ab1685a942d82a7905f01ba02\" ),     # html_files\n",
    "    (1_744, \"038c464e3f3f2994ce3beda0ae0428bf\" ),\n",
    "    (1_684, \"dfa71e97d8fe66456b4ad518c897c024\" ),\n",
    "    (1_669, \"6f996d51f9194252b646beea573aa3ae\" ),\n",
    "    (1_665, \"8b6c9cccfc650ab202aeef7807df7c21\" ),\n",
    "    (1_613, \"0f3cfa31850c1d36a42b46aa47a9c659\" ),\n",
    "    (1_608, \"fd392ce9e6a30c3edb86b22e297be001\" ),\n",
    "    (1_600, \"bdcc1e25cc8eb91bf2f01b268878c888\" ),\n",
    "    (950, \"78ecf9f0b85511d82f0b0d2d28b45cb1\" ),\n",
    "    (796, \"7c1c5b35726e05fff4a9d0d96314eb93\" ),\n",
    "    (429, \"e67c90a18c89f8d05125c045b2978dcf\" ),\n",
    "    (241, \"e73df154bb8d5f13aa4b1a6fbd1057eb\" ),\n",
    "    (43, \"fc94fb0c3ed8a8f909dbc7630a0987ff\" ),\n",
    "    (16, \"c630b0d2ea3415b07989b13bf3ae7e5a\" ),\n",
    "    (24_446, \"07fbdbd97b38c3a1dc0d6315e616459c\" ),\n",
    "    (7_935, \"b8173660d6918dcae3757f87b01ba37a\" ),\n",
    "    (2_747, \"a7056b3db0858592f1afc18198aa6792\" ),\n",
    "    (2_720, \"9b767e01abde4f96805a6b79d85bdb11\" ),\n",
    "    (2_484, \"cc53cf96c0614d2f455124fb6e47f564\" ),\n",
    "    (1_260, \"d835db4ea8ec417b9ee9a4b1011dda32\" ),\n",
    "    (772, \"814865989fbf9cd423aacfca087bc985\" ),\n",
    "    (327, \"0813bb506f592f948ac7fca2aebd8375\" ),\n",
    "    (250_378, \"649d385019e958f2dc449d760eae1433\" ),\n",
    "    (44_402, \"b8e32154eb85161d798a482698a3a15a\" ),\n",
    "    (27_504, \"3a972b87d3e06de52394236dc40dac17\" ),\n",
    "    (24_546, \"5ce44fe0141243fe8b8954d313487d6d\" ),\n",
    "    (19_569, \"4a30bda8c53d7ad79cc1c9fdc20853ac\" ),\n",
    "    (6_857, \"38bdf450941e648c78f5c44180d2c6b5\" ),\n",
    "    (5_443, \"cc58acc7fee92cf8ad71bcfc865929f1\" ),\n",
    "    (2_055, \"981964fc97de33907aa8a792e0ef8a58\" ),\n",
    "    (1_499, \"f284a5859416c774e292e322eca10342\" ),\n",
    "    (1_360, \"49a185c3d50e6344ed830c35362daf19\" ),\n",
    "    (857, \"0adde11c2b3ab22644513a861673a175\" ),\n",
    "    (698, \"484f6cd068e3aa8b917b9d3ae94287f7\" ),\n",
    "    (615, \"df5b7b300059ac33fd4eac219bf7d7e8\" ),\n",
    "    (441, \"c7041b531508730ad1ec6f79af96e016\" ),\n",
    "    (108, \"67c58a38087e1a243fd14984f663b520\" ),\n",
    "    (43, \"9bb191c6827273aa978cab39a3587950\" ),\n",
    "    (11_314, \"06cec7c2dcebe067cc9c48459a44c3b3\" ),\n",
    "    (1_731, \"1d64c32dda48159518461bbfd44b890c\" ),\n",
    "    (9_068, \"7db84acc1f8d8b7b8f113329b2fcf7a2\" ),\n",
    "    (986, \"845f45f83bea424bdd568b572d41bdff\" ),\n",
    "    (371, \"35f5dabb3310f74a016e9e742af42784\" ),\n",
    "    (157, \"2f644fe56705ccebca516a1d0c3524a8\" ),\n",
    "    (140, \"813a7f41542bfe7da4ff1aab9518c0a0\" ),\n",
    "    (138, \"2099cba4cfa03a795700942562325baa\" ),\n",
    "    (138, \"2b37d2b8ee9c5334b10d43117de6d030\" ),\n",
    "    (136, \"722089ca67a897ba0967f4c49b730846\" ),\n",
    "    (136, \"72793f10acd9594091f44ed1e66ae4c9\" ),\n",
    "    (6_159, \"f98fb2daa8efdabe2dbb4d4b847f6b93\" ),\n",
    "    (931, \"1b60df911d0b2709a27f3298db7643e5\" ),\n",
    "    (860, \"a0cfa2acd631063a5ce7b8cb6788e8c9\" ),\n",
    "    (43, \"ad4b0f606e0f8465bc4c4c170b37e1a3\" ),\n",
    "    (43, \"b4491705564909da7f9eaf749dbbfbb1\" ),\n",
    "    (35, \"d57de1bd97baaffb63fe2a0602c03cbf\" ),\n",
    "    (475_729, \"fb0a6fac20c9ac1f5a53dfe98f8cc03b\" ), # html_files 3ds-max\n",
    "    (352_022, \"85e6575536361ab55add63590e7b1b23\" ),\n",
    "    (328_466, \"0b9b2c3a50c8d6d7f62c4e7e4c9e624f\" ),\n",
    "    (305_231, \"6dc137a38f5f7e99491f97aefdd1408b\" ),\n",
    "    (91_357, \"964f6c5c67eecee8b89e87d204746a36\" ),\n",
    "    (91_243, \"52ccb9dbfbb5acd479c689bcb0bb821d\" ),\n",
    "    (75_451, \"43dc8d745cb88d102d27133d35a28216\" ),\n",
    "    (65_281, \"a6bdab3aa4e5b9d6d4d5413e50aa896d\" ),\n",
    "    (36_788, \"8c3e276d43f9d154193d5b009944046b\" ),\n",
    "    (27_665, \"54b6fef5e581b03d08f91e30c9cc9720\" ),\n",
    "    (26_339, \"d96d87c99db49fa4e65afbff685f2b79\" ),\n",
    "    (24_473, \"35e5d2aff2f32c533cd834fc483a44d2\" ),\n",
    "    (14_694, \"ef6bc825fb7d1a523994895c5ca5c1d8\" ),\n",
    "    (14_428, \"cc9baf55a5ae241e0c31f3f48173c4e2\" ),\n",
    "    (12_783, \"8e6eba6b41e432bfe59a9f19f0856c8e\" ),\n",
    "    (10_306, \"81a7b377bfc310fc3b7999d0132f66e6\" ),\n",
    "    (10_001, \"73668d4d0b9150a500bdb461c7e83542\" ),\n",
    "    (8_431, \"29c66274d96710aaa1f537f313f208f3\" ),\n",
    "    (7_355, \"c103190fc64ae07467f9473d49ca522f\" ),\n",
    "    (5_854, \"ad44007be5e39529077868bf0d1e1fa8\" ),\n",
    "    (4_311, \"2489f2e86c13a322f93a8dbc92aa6818\" ),\n",
    "    (3_588, \"cc87e45f6a4cffe09bf42a633b7d1975\" ),\n",
    "    (3_153, \"15fd5d53d04ee079fd64d76f0d8fe6ff\" ),\n",
    "    (3_070, \"981cd5c338a169682bf9e7e075a3c4bd\" ),\n",
    "    (2_153, \"056a277b9cf88c08ede52224afa2e243\" ),\n",
    "    (2_062, \"69b9645b92ebf920e8c8cb1fb667497d\" ),\n",
    "    (1_009, \"ba89910181ce7b387e172784ce2f0bad\" ),\n",
    "    (750, \"71be19e25403369a5a3d1420c918c3ab\" ),\n",
    "    (307, \"d8e2d40de34f54b587630b4bb4f716cf\" ),\n",
    "    (171, \"0242a8d9c4f049cd30755a0f92702ed6\" ),\n",
    "    (28, \"603dfdbdae47add9d387f3e68ba95db9\" ),\n",
    "    (50_600, \"3ab543d2ce4b78e185d96ddca865d6b4\" ), # html_files msdn\n",
    "    (49_210, \"ef0721a630043c0915eae6d7c3d42bf8\" ),\n",
    "    (27_035, \"c764fa3d6b8a84bd40aa131355215c98\" ),\n",
    "    (14_512, \"7dd5010625d10aecaab21b9f1162cbae\" ),\n",
    "    (12_301, \"f47b71b086bba5822af542fa7101aa50\" ),\n",
    "    (4_203, \"8e010b67ceb176b577f5afa1ceb6f5ad\" ),\n",
    "    (1_399, \"b97c6c870866d885285a9916fb11ca37\" ),\n",
    "    (493, \"0d0542f5f45cf9fc7273abd11cf5c0ee\" ),\n",
    "    (186, \"9166785a2d662ca4c0379dcbb5813e69\" ),\n",
    "    (85, \"030c41d9079671d09a62d8e2c1db6973\" ),\n",
    "    (255, \"5ea4487e38d947beabed2fabac01985d\" ), # html_files ядерка в картинках\n",
    "    (70, \"fa74e5c9eef0c6bcc042b3566e6f8a71\" ),\n",
    "    (70, \"9814720c2787382e0f6a5323ee2dd04d\" ),\n",
    "    (70, \"0b1d98eea461d796574f291c97874a58\" ),\n",
    "    (67, \"3539ce8e0ab777f345ebf7f4ceebcdbc\" ),\n",
    "    (66, \"55f94d685494301179aac9ebeda1903d\" ),\n",
    "    (65, \"eeddd315c785c1da6c843a8857d877f4\" ),\n",
    "    (64, \"0500eb7c6f993f64bb3e99b30859d26f\" ),\n",
    "    (63, \"186af931b79af9927ff562bb0064a1d0\" ),\n",
    "    (62, \"a0aa32fab42e0d271bdec9f450f36a80\" ),\n",
    "    (61, \"6a1fe643d61cca0347ebc1021e295861\" ),\n",
    "    (61, \"24183c0285561fffd74ee694ea9c8024\" ),\n",
    "    (61, \"3e1c99a277fb93295d749b6b347e3877\" ),\n",
    "    (60, \"dec5318b5b5f857a9851c897ba6ce037\" ),\n",
    "    (59, \"2757ff4b1f96badb43b79ee4ad10e6e5\" ),\n",
    "    (58, \"c3826e3595941d0f2eb7605a2efdb4b0\" ),\n",
    "    (55, \"8fc4994fe73c12335f988c6d45963627\" ),\n",
    "    (54, \"e5376996a7458b2b53f2301651fad64d\" ),\n",
    "    (53, \"21d0dcc329e631f70451355ba787a330\" ),\n",
    "    (896, \"9ad22f411108f2aa673ffc7e8bf658a7\" ),\n",
    "    (116, \"a12b6e532e4d856d8495f0fa3ed809aa\" ),\n",
    "    (116, \"e453dec490462ec6799516646515ef3d\" ),\n",
    "    (76, \"bf941b9277599664124688dd04690c30\" ),\n",
    "    (73, \"616363f7cf2230203bf297d9b54646fa\" ),\n",
    "    (73, \"b4e00279ee5f87d6904063c003f60aa0\" ),\n",
    "    (72, \"44cda4626cf69c3b55ccd756fafb53cb\" ),\n",
    "    (69, \"08ce127d77bfa71ee2b1bb2bf51144dd\" ),\n",
    "    (63, \"aa0f1b642fc3e8830e0fce3c6a8f112d\" ),\n",
    "    (61, \"849f4554c3e7d997211d357435d5530f\" ),\n",
    "    (59, \"4878626af6b7f618487a73e5ba1d52b0\" ),\n",
    "    (58, \"c1abd383cd5df3f72640d9fd5f1422ed\" ),\n",
    "    (58, \"af171591a40928b3e7c854578ab21a1c\" ),\n",
    "    (35_147, \"d32239bcb673463ab874e80d47fae504\" ), # COPYING.GPL\n",
    "    (0, \"d41d8cd98f00b204e9800998ecf8427e\" ),      # size==0\n",
    "    (66_501, \"414faddd4014819a28da4e05e96c1dbc\" ), # borland\n",
    "    (18_063, \"9ec015b7f53ef492357b02583a4c7061\" ),\n",
    "    (17_355, \"0be1b2d5b4c2ad31ed678694a949773f\" ),\n",
    "    (16_677, \"a6d500698ba9b68e904392c3b3aa9b8f\" ),\n",
    "    (14_670, \"a49bca341f3cb3baab6c8b132aefed6a\" ),\n",
    "    (13_596, \"04aa2c7082c5bf66da8d60e1fc214443\" ),\n",
    "    (10_987, \"a5340e563dbf2429d6017076b86ceadc\" ),\n",
    "    (12_083, \"4b001ca5a391481deebfdb19cf365880\" ),\n",
    "    (8_439, \"2f3c50c65dff32d69e2f60c352a670c8\" ),\n",
    "    (8_437, \"d09b538e0278d8fd934cfa25b6ea2b7b\" ),\n",
    "    (5_554, \"738cda3ae2949ee902f8d55b6021d868\" ),\n",
    "    (5_131, \"f53a2b6f38f1098fefe4397b3bd31759\" ),\n",
    "    (2_477, \"c85d88caf0a8e6c9fed060fd079604f2\" ),\n",
    "    (2_474, \"fd209bbeb1ec7d7a13f26a375dc47bfc\" ),\n",
    "    (2_309, \"c2a8df8aff9076fd317796c08090a256\" ),\n",
    "    (2_253, \"6550325d56f536ff49db63f15dc2d944\" ),\n",
    "    (878, \"fde39708905c7b6ffe7cc137714ead0f\" ),   # msvc manifest\n",
    "    (1_425, \"8a24adb3dc806e3f026fc641d43c5b72\" ),\n",
    "    (1_417, \"a65e8754601de76b02a3cc2819aab3ef\" ),\n",
    "    (728, \"e70025a7266b35ba4b48407fc688fd2c\" ),\n",
    "    (663, \"9f97434014566363118e883726f603ff\" ),\n",
    "    (621, \"8da3fa81efa85adad78efc1d31537d2a\" ),\n",
    "    (1_429, \"fee0e8889be26bc72132a97a64454b29\" ),\n",
    "    (1_413, \"dfdbe8f9224050b2637342425f9f1d2a\" ),\n",
    "    (2_048, \"e1bf2cb8445d93d66209b6a06a2dc941\" ),\n",
    "\n",
    "    (3_962, \"7fa92bb6f9a1d90d96b03937c01d49f9\" ), # msvc грамматика с++\n",
    "    (899, \"825bee862b469247c8afc1c0b0adb624\" ),   # msvc грамматика с++\n",
    "\n",
    "    (13_998, \"9d5ae975ae461be51dfd41d904c52af2\" ),# gnu build scripts\n",
    "    (10_346, \"52cc47fe5f31e22f14f911caaf821429\" ),# gnu build scripts\n",
    "    \n",
    "    (753, \"87490c36908663abfee7896b356fda81\" ), # puasson & прак полупроводниковый детектор\n",
    "    \n",
    "    (318_956, \"e5d2b7f46c4800a32f62ce75676a5710\" ), # QC .jar\n",
    "    \n",
    "    (4_951, \"81005745454846bb79cc3c7c0c57658d\" ), # git sample\n",
    "    (3_610, \"517f14b9239689dff8bda3022ebd9004\" ),\n",
    "    (1_642, \"01b1688f97f94776baae85d77b06048b\" ),\n",
    "    (1_348, \"3c5989301dd4b949dfa1f43738a22819\" ),\n",
    "    (1_239, \"7dfe15854212a30f346da5255c1d794b\" ),\n",
    "    (896, \"579a3c1e12a1e74a98169175fb913012\" ),\n",
    "    (478, \"ce562e08d8098926a3862fc6e7905199\" ),\n",
    "    (424, \"054f9ffb8bfe04a599751cc757226dda\" ),\n",
    "    (240, \"036208b4a1ab4a235d75c181e685e5a3\" ),\n",
    "    (189, \"2b7ea5cee3c49ff53d41e00785eb974c\" ),\n",
    "    (73, \"a0a7c3fff21f2aea3cfa1d0316dd816c\" ),\n",
    "    (32, \"73a00957034783b7b5c8294c54cd3e12\" ),\n",
    "    (23, \"4cf2d64e44205fe628ddd534e1151b58\" ),\n",
    "    (25, \"5ab7a4355e4c959b0c5c008f202f51ec\" ),\n",
    "    (34, \"b501512a260537c5e52df65d2a034251\" ),\n",
    "    (4_898, \"56e45f2bcbc8226d2b4200f7c46371bf\" ),\n",
    "    (3_327, \"ecbb0cb5ffb7d773cd5b2407b210cc3b\" ),\n",
    "    (1_638, \"e4db8c12ee125a8a085907b757359ef0\" ),\n",
    "    (1_492, \"2b5c047bdb474555e1787db32b2d2fc5\" ),\n",
    "    (544, \"2ad18ec82c20af7b5926ed9cea6aeedd\" ),\n",
    "    \n",
    "    (4_996, \"54b3964dbdd5e0595cf51a0d837a13d2\" ), # mocha.css\n",
    "    (258_388, \"56f1d01ee4bb68d1572cfd60755cf67a\" ), # jquery-2.2.0.js\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-11T13:05:57.394841Z",
     "start_time": "2019-11-11T13:05:57.283834Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "ignored_dirs = {\n",
    "    r'D:\\Users\\feelus\\YandexDisk\\_programming\\_сети\\_networks\\Томсон Л.Разработка WEB-приложений на PHP и MySQL.Диасофт.[RUS,672с.,2003]\\Томсон Л.Разработка WEB-приложений на PHP и MySQL.CD',\n",
    "    r'D:\\Users\\feelus\\YandexDisk\\_programming_arxiv\\src_sample\\corba\\mico',\n",
    "    r'D:\\Users\\feelus\\YandexDisk\\_programming_arxiv\\lang_java\\jdk1.7.0_02',\n",
    "    r'D:\\Users\\feelus\\YandexDisk\\_физика\\3_квантовые вычисления\\QC\\_QuantumCirquits\\qcs-code',\n",
    "    r'D:\\Users\\feelus\\YandexDisk\\_физика\\3_квантовые вычисления\\QC\\bloch3dapp\\osx-x86\\jogl\\lib',\n",
    "    r'D:\\Users\\feelus\\YandexDisk\\программы-установщики\\_дрова\\v10_1200a (VIA HD Audio UAA Driver)\\VIAHDAud\\Present',\n",
    "    r'D:\\Users\\feelus\\YandexDisk\\программы-установщики\\_дрова\\motherboard_GIGABYTE\\drivers\\VGA',\n",
    "    r'D:\\Users\\feelus\\YandexDisk\\программы-установщики\\_дрова\\motherboard_GIGABYTE\\drivers\\Raid\\ITE_RAID',\n",
    "    r'D:\\Users\\feelus\\YandexDisk\\программы-установщики\\_дрова\\дрова для планшета\\wifi\\Atheros_Bluetooth_Drivers_8.0.0.214',\n",
    "    r'D:\\Users\\feelus\\YandexDisk\\программы-установщики\\_дрова\\L210_SCNDRV_3.7.9.1_Win_Home7_Nordic4_East9_TR_EL_RU_UK_AR_CA',\n",
    "    r'D:\\Users\\feelus\\YandexDisk\\программы-установщики\\_дрова\\motherboard_GIGABYTE\\drivers\\LAN\\Marvell\\Other Driver',\n",
    "    r'D:\\Users\\feelus\\YandexDisk\\программы-установщики\\_крякнутые\\MatLab 701-2004',\n",
    "    r'D:\\Users\\feelus\\YandexDisk\\_programming\\_web\\javascript_goo',\n",
    "    r'D:\\Users\\feelus\\YandexDisk\\_programming_arxiv\\lang_bash\\bash_src',\n",
    "    r'D:\\Users\\feelus\\YandexDisk\\_programming\\__криптография',\n",
    "    r'D:\\Users\\feelus\\YandexDisk\\_programming\\_lang_cpp\\lib_glib-2.32.3',\n",
    "    r'D:\\Users\\feelus\\YandexDisk\\_programming\\_lang_cpp\\lib_QT\\Шлее М.Qt4 профессиональное программирование на  C++.БХВ.[RUS,880p.,2007]',\n",
    "    r'D:\\Users\\feelus\\YandexDisk\\_programming\\_lang_cpp\\lib_QT\\Марк Саммерфилд - Qt Профессиональное программирование (High tech) - 2011',\n",
    "    r'D:\\Users\\feelus\\YandexDisk\\_programming\\_lang_c\\cpp',\n",
    "    r'D:\\Users\\feelus\\YandexDisk\\_programming\\form_course',\n",
    "    r'D:\\Users\\feelus\\YandexDisk\\crossingover\\crossingover\\фото\\фото-нумерованное',\n",
    "    r'D:\\Users\\feelus\\YandexDisk\\crossingover\\crossingover\\фото\\poses',\n",
    "    r'D:\\Users\\feelus\\YandexDisk\\программы-установщики\\_дрова',\n",
    "    r'D:\\Users\\feelus\\Repos\\muzon\\.git',\n",
    "    r'D:\\Users\\feelus\\Repos\\__my_repos\\parser\\.git',\n",
    "    r'D:\\Users\\feelus\\Repos\\__my_forked\\Instantfox\\.git',\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# On One Disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-11-11T13:05:52.915Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3eba92597fe04fd49b7e5bf72c4b9395",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HTML(value='')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "can't check stat of file: D:\\\\$RECYCLE.BIN\\S-1-5-21-281476240-1351446808-3602091694-1000\\$R80B473\n",
      "can't check stat of file: D:\\\\$RECYCLE.BIN\\S-1-5-21-281476240-1351446808-3602091694-1000\\$RHEH575\n",
      "can't check stat of file: D:\\\\$RECYCLE.BIN\\S-1-5-21-281476240-1351446808-3602091694-1000\\$RSMWGH3\n",
      "can't check stat of dir: D:\\\\$RECYCLE.BIN\\S-1-5-21-281476240-1351446808-3602091694-1000\\$R4OOHHK\\assets\\objects\\89\n"
     ]
    }
   ],
   "source": [
    "if 1:\n",
    "    root = {}\n",
    "    rootpath_YD_list_list = set()\n",
    "\n",
    "if 0: # 35s +  7s :   682.337 MB 579.163 MB 31367    24864\n",
    "    rootpath_YD = r'D:\\Users\\feelus\\YandexDisk'\n",
    "    root_YD = scan(rootpath_YD)\n",
    "    root['D:'] = {}\n",
    "    root['D:']['Users'] = {}\n",
    "    root['D:']['Users']['feelus'] = {}\n",
    "    root['D:']['Users']['feelus']['YandexDisk'] = root_YD\n",
    "    rootpath_YD_list = ['D:','Users','feelus','YandexDisk']\n",
    "    rootpath_YD_list_list.add(tuple(rootpath_YD_list))\n",
    "    hash_YD = 'hash_cash_YD.json'\n",
    "\n",
    "if 1: # 5m 21s + 2m 37s :   11638.450 MB 6810.797 MB 174977    124404\n",
    "    # 4m 21s + 1m 54s:   10973.443 MB 6669.114 MB 175843    128178\n",
    "    rootpath_YD = r'D:\\\\'\n",
    "    root_YD = scan(rootpath_YD)\n",
    "    if '$RECYCLE.BIN' in root_YD:\n",
    "        del root_YD['$RECYCLE.BIN']\n",
    "    root['D:'] = root_YD\n",
    "    rootpath_YD_list = ['D:']\n",
    "    rootpath_YD_list_list.add(tuple(rootpath_YD_list))\n",
    "    hash_YD = 'hash_cash_D.json'\n",
    "\n",
    "if 0:# 54s + 47s : \n",
    "    rootpath_YD = r'H:\\yadisks'\n",
    "    root_YD = scan(rootpath_YD)\n",
    "    root['H:'] = {}\n",
    "    root['H:']['yadisks'] = root_YD\n",
    "    #root['H:']['yadisks']['2019'] = {}\n",
    "    #root['H:']['yadisks']['2019']['_programming_arxiv'] = root_YD\n",
    "    rootpath_YD_list = ['H:','yadisks']#,'2019','_programming_arxiv']\n",
    "    rootpath_YD_list_list.add(tuple(rootpath_YD_list))\n",
    "    hash_YD = 'hash_cash.json'\n",
    "if 1:\n",
    "    rootpath_YD = r'H:'\n",
    "    root_YD = scan(rootpath_YD)\n",
    "    if '$RECYCLE.BIN' in root_YD:\n",
    "        del root_YD['$RECYCLE.BIN']\n",
    "    root['H:'] = root_YD\n",
    "    #root['H:']['yadisks']['2019'] = {}\n",
    "    #root['H:']['yadisks']['2019']['_programming_arxiv'] = root_YD\n",
    "    rootpath_YD_list = ['H:']#,'2019','_programming_arxiv']\n",
    "    rootpath_YD_list_list.add(tuple(rootpath_YD_list))\n",
    "    hash_YD = 'hash_cash.json'\n",
    "\n",
    "if 1:\n",
    "    rootpath_YD = r'I:'\n",
    "    root_YD = scan(rootpath_YD)\n",
    "    if '$RECYCLE.BIN' in root_YD:\n",
    "        del root_YD['$RECYCLE.BIN']\n",
    "    root['I:'] = root_YD\n",
    "    rootpath_YD_list = ['I:']\n",
    "    rootpath_YD_list_list.add(tuple(rootpath_YD_list))\n",
    "    hash_YD = 'hash_cash.json'\n",
    "\n",
    "if 1:\n",
    "    # YD+HYD:  51.3s + \n",
    "    \n",
    "    # H+I:    26m 28s +     3m 50s :  63955.552 MB  40_354.847 MB  406134    254424\n",
    "    # D+H+I:  23m 46s + 4h 13m 47s : 272892.752 MB 152_887.327 MB 1225489    778638\n",
    "    root_YD = root\n",
    "    rootpath_YD_list = []\n",
    "    hash_YD = 'hash_cash.json'\n",
    "else:\n",
    "    if len(rootpath_YD_list_list)==1:\n",
    "        rootpath_YD_list_list = next(iter(rootpath_YD_list_list))\n",
    "    else:\n",
    "        raise BasicException('qwe')\n",
    "\n",
    "len(root_YD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-11-11T13:05:52.919Z"
    }
   },
   "outputs": [],
   "source": [
    "print('size in memory:',getmemsize(root_YD)/1024/1024,'MB')\n",
    "\n",
    "root_YD_by_size,dups_YD_by_size = get_diplics_by_size(root_YD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-11-11T13:05:52.923Z"
    }
   },
   "outputs": [],
   "source": [
    "old_root = load_hashes(hash_YD,rootpath_YD_list_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-11-11T13:05:52.932Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "calculated = calc_hashes(root,old_root,rootpath_YD_list_list,root_YD_by_size,dups_YD_by_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-11-11T13:05:52.936Z"
    }
   },
   "outputs": [],
   "source": [
    "unload_hashes(root,hash_YD,rootpath_YD_list_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-11-11T13:05:52.941Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dups_YD_by_hash = get_duplics_by_hash(root_YD,root_YD_by_size,dups_YD_by_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-11-11T13:05:52.945Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from copy import copy,deepcopy\n",
    "dups_YD_by_hash_cp = deepcopy(dups_YD_by_hash)\n",
    "root_cp = deepcopy(root)\n",
    "\n",
    "ignore_files(dups_YD_by_hash_cp)\n",
    "ignore_dirs(root_cp,rootpath_YD_list_list,dups_YD_by_hash_cp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-11-11T13:05:52.950Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "if type(rootpath_YD_list_list)==set:\n",
    "    rootpath_YD = ''\n",
    "count = 0\n",
    "for s_h,pp in dups_YD_by_hash_cp.items():\n",
    "    s,h = s_h\n",
    "    for p in pp:\n",
    "        if count<100 and is_subpath(p,r'D:\\Users\\feelus\\YandexDisk'.split('\\\\')):\n",
    "          #p[0]=='Users':# and p[1]=='Users':# and p[2]=='Repos':\n",
    "            count+=1\n",
    "            ss = str(s)\n",
    "            ss = ss if len(ss)<=3 else\\\n",
    "                ss[:-3]+'_'+ss[-3:] if len(ss)<=6 else\\\n",
    "                ss[:-6]+'_'+ss[-6:-3]+'_'+ss[-3:]\n",
    "            print('\\t('+ss+', \"'+h+'\" ),')\n",
    "            for q in pp:\n",
    "                if rootpath_YD=='':\n",
    "                    print((my_path_join_l(list(q))))\n",
    "                else:\n",
    "                    #print([rootpath_YD]+list(q))\n",
    "                    print((my_path_join_l([rootpath_YD]+list(q))))\n",
    "            break\n",
    "if count==100: print('...')\n",
    "else:          print('--- the end ---')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Повторное"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-11-11T13:05:52.956Z"
    }
   },
   "outputs": [],
   "source": [
    "raise BaseException(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-11-11T13:05:52.960Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def upd_dir(root,dir_upd):\n",
    "    root_upd = scan(dir_upd)\n",
    "    dir_upd = dir_upd.split('\\\\')\n",
    "    tmp_root = get_subtree(root,dir_upd[:-1])\n",
    "    tmp_root[dir_upd[-1]] = root_upd\n",
    "\n",
    "#upd_dir(root,r'H:\\_музыка')\n",
    "upd_dir(root,r'I:\\_downloads\\Downloads')\n",
    "\n",
    "#print('size in memory:',getmemsize(root_YD)/1024/1024,'MB')\n",
    "\n",
    "root_YD_by_size,dups_YD_by_size = get_diplics_by_size(root_YD)\n",
    "\n",
    "calculated = calc_hashes(root,old_root,rootpath_YD_list_list,root_YD_by_size,dups_YD_by_size)\n",
    "\n",
    "dups_YD_by_hash = get_duplics_by_hash(root_YD,root_YD_by_size,dups_YD_by_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-11-11T13:05:52.964Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if 1:\n",
    "    del_dir(root,rootpath_YD_list_list,dups_YD_by_hash,\n",
    "    r'D:\\Users\\feelus\\Repos\\__my_forked\\jjv', \n",
    "    #r'D:\\Users\\feelus\\cyg-home\\src\\jjv',\n",
    "    r'I:\\_cygwin-home\\homePChome-cy\\src\\jjv-instance',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-11-11T13:05:52.968Z"
    }
   },
   "outputs": [],
   "source": [
    "#calculated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-11-11T13:05:52.972Z"
    }
   },
   "outputs": [],
   "source": [
    "len(calculated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-11-11T13:05:52.977Z"
    },
    "code_folding": [],
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "if type(rootpath_YD_list_list)==set:\n",
    "    rootpath_YD = ''\n",
    "count = 0\n",
    "for s_h,pp in dups_YD_by_hash.items():\n",
    "    s,h = s_h\n",
    "    for p in pp:\n",
    "        if count<100 and s_h not in ignored_files\\\n",
    "          and is_subpath(p,r'D:\\Users\\feelus\\Downloads\\__всякое'.split('\\\\')):\n",
    "          #p[0]=='Users':# and p[1]=='Users':# and p[2]=='Repos':\n",
    "            lc = 0\n",
    "            for q in pp:\n",
    "                for ip in ignored_dirs:\n",
    "                    #print(q,ip.split('\\\\'))\n",
    "                    if is_subpath(q,ip.split('\\\\')):\n",
    "                        lc+=1\n",
    "                        break\n",
    "            #print('lc=',lc)\n",
    "            if len(pp)-lc < 2:\n",
    "                break\n",
    "            count+=1\n",
    "            ss = str(s)\n",
    "            ss = ss if len(ss)<=3 else\\\n",
    "                ss[:-3]+'_'+ss[-3:] if len(ss)<=6 else\\\n",
    "                ss[:-6]+'_'+ss[-6:-3]+'_'+ss[-3:]\n",
    "            print('\\t('+ss+', \"'+h+'\" ),')\n",
    "            for q in pp:\n",
    "                cont = False\n",
    "                for ip in ignored_dirs:\n",
    "                    if is_subpath(q,ip):\n",
    "                        cont = True\n",
    "                        break\n",
    "                if cont:\n",
    "                    continue\n",
    "                if rootpath_YD=='':\n",
    "                    print((my_path_join_l(list(q))))\n",
    "                else:\n",
    "                    #print([rootpath_YD]+list(q))\n",
    "                    print((my_path_join_l([rootpath_YD]+list(q))))\n",
    "            break\n",
    "if count==100: print('...')\n",
    "else:          print('--- the end ---')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-11-11T13:05:53.005Z"
    }
   },
   "outputs": [],
   "source": [
    "#get_subtree(root,\n",
    "#            r'D:\\Users\\feelus\\YandexDisk\\_programming_arxiv\\_разное\\_javascript\\backup\\start_goo_files'\\\n",
    "#            .split('\\\\'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-11-11T13:05:53.010Z"
    }
   },
   "outputs": [],
   "source": [
    "#get_subtree(root,\n",
    "#            r'D:\\Users\\feelus\\YandexDisk\\_programming_arxiv\\_разное\\_javascript\\javascript_goo\\backup\\start_goo_files'\\\n",
    "#            .split('\\\\'))"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
